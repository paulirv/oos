# EU AI Act — Content Labeling Landscape

Regulatory context for AI content transparency.

## Status: Draft

## Relevant Provisions

The EU AI Act includes requirements for:
- Labeling AI-generated content (deep fakes, synthetic media)
- Transparency obligations for AI systems
- Marking AI-generated or manipulated content

## OOS Relationship

OOS is positioned as the **best-practice standard that exceeds regulatory minimums**.

| Aspect | EU AI Act | OOS |
|--------|-----------|-----|
| Scope | AI-generated content in EU | All content, worldwide |
| Requirement | Binary label: AI-generated or not | Spectrum of origin categories |
| Enforcement | Regulatory (fines) | Self-declaration (like WCAG) |
| Granularity | Coarse | L1 (coarse) to L3 (detailed) |
| Audience | Regulated entities | Any publisher |

## Strategic Positioning

1. **OOS L1 satisfies EU requirements** — The basic origin category covers the binary classification EU requires
2. **OOS goes further** — L2 and L3 provide nuance that regulation doesn't require but consumers value
3. **OOS is voluntary** — Adoption is driven by value, not compliance
4. **OOS is global** — Not jurisdiction-specific

## Key Insight

Regulation creates the floor. OOS defines the ceiling. Publishers who want to demonstrate leadership on transparency use OOS. Publishers who just need compliance check the regulatory box.

## Research Questions

- [ ] What are the specific technical requirements for AI content labeling in the EU AI Act?
- [ ] When do the content labeling provisions take effect?
- [ ] Are there other jurisdictions with similar requirements?
- [ ] Does the EU AI Act specify a format for labeling?
